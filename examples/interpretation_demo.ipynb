{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Transformer Embedding Interpretation Demo\n",
    "\n",
    "This notebook demonstrates how to interpret transformer embeddings at the level of style and semantics using the Interpretations-of-Transformers framework.\n",
    "\n",
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "\n",
    "# Add src to path\n",
    "sys.path.insert(0, os.path.join(os.path.dirname(os.getcwd()), 'src'))\n",
    "\n",
    "from embedding_interpreter import TransformerEmbeddingInterpreter\n",
    "from visualization import plot_style_comparison, plot_semantic_space, plot_comprehensive_analysis\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "print(\"✓ Modules imported successfully\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initialize the Interpreter\n",
    "\n",
    "We'll use BERT as our base transformer model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize interpreter with BERT\n",
    "interpreter = TransformerEmbeddingInterpreter(model_name=\"bert-base-uncased\")\n",
    "\n",
    "print(f\"Model: {interpreter.model_name}\")\n",
    "print(f\"Device: {interpreter.device}\")\n",
    "print(\"✓ Interpreter initialized successfully\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example 1: Style Analysis\n",
    "\n",
    "Let's analyze texts with different writing styles."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define texts with different styles\n",
    "formal_texts = [\n",
    "    \"The research demonstrates significant improvements in natural language processing methodologies.\",\n",
    "    \"Our experimental findings indicate a substantial enhancement in overall model performance metrics.\",\n",
    "    \"The quantitative analysis reveals statistically significant results across all evaluation benchmarks.\"\n",
    "]\n",
    "\n",
    "informal_texts = [\n",
    "    \"This AI stuff is really cool and it's getting better every single day!\",\n",
    "    \"I can't believe how awesome these language models are becoming lately.\",\n",
    "    \"It's amazing to see how far we've come with this technology!\"\n",
    "]\n",
    "\n",
    "print(\"Formal texts:\")\n",
    "for i, text in enumerate(formal_texts, 1):\n",
    "    print(f\"{i}. {text}\")\n",
    "\n",
    "print(\"\\nInformal texts:\")\n",
    "for i, text in enumerate(informal_texts, 1):\n",
    "    print(f\"{i}. {text}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analyze formal texts\n",
    "formal_analysis = interpreter.analyze_style(formal_texts)\n",
    "\n",
    "print(\"Formal Text Analysis:\")\n",
    "print(f\"  Mean Formality: {formal_analysis['formality']['mean_formality']:.3f}\")\n",
    "print(f\"  Mean Complexity: {formal_analysis['complexity']['mean_complexity']:.3f}\")\n",
    "print(f\"  Sentiment: {formal_analysis['sentiment']['polarity']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analyze informal texts\n",
    "informal_analysis = interpreter.analyze_style(informal_texts)\n",
    "\n",
    "print(\"Informal Text Analysis:\")\n",
    "print(f\"  Mean Formality: {informal_analysis['formality']['mean_formality']:.3f}\")\n",
    "print(f\"  Mean Complexity: {informal_analysis['complexity']['mean_complexity']:.3f}\")\n",
    "print(f\"  Sentiment: {informal_analysis['sentiment']['polarity']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize style analysis\n",
    "plot_style_comparison(\n",
    "    formal_analysis,\n",
    "    labels=[f\"Formal {i}\" for i in range(1, len(formal_texts) + 1)]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example 2: Semantic Analysis\n",
    "\n",
    "Let's analyze the semantic content and relationships in technical texts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Technical texts on related topics\n",
    "technical_texts = [\n",
    "    \"The transformer architecture utilizes self-attention mechanisms for sequence modeling.\",\n",
    "    \"Neural networks employ backpropagation for gradient descent optimization.\",\n",
    "    \"BERT uses bidirectional transformers to learn contextual word representations.\",\n",
    "    \"Machine learning algorithms can identify patterns in large datasets.\",\n",
    "    \"Deep learning models require substantial computational resources for training.\"\n",
    "]\n",
    "\n",
    "print(\"Technical texts:\")\n",
    "for i, text in enumerate(technical_texts, 1):\n",
    "    print(f\"{i}. {text}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Perform semantic analysis\n",
    "semantic_analysis = interpreter.analyze_semantics(technical_texts)\n",
    "\n",
    "print(\"Semantic Analysis Results:\")\n",
    "print(f\"  Coherence Score: {semantic_analysis['coherence']['coherence_score']:.3f}\")\n",
    "print(f\"  Interpretation: {semantic_analysis['coherence']['interpretation']}\")\n",
    "print(f\"  Mean Similarity: {semantic_analysis['similarity_matrix']['mean_similarity']:.3f}\")\n",
    "\n",
    "if 'clusters' in semantic_analysis:\n",
    "    print(f\"  Number of Clusters: {semantic_analysis['clusters']['n_clusters']}\")\n",
    "    print(f\"  Cluster Distribution: {semantic_analysis['clusters']['cluster_sizes']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize semantic space\n",
    "plot_semantic_space(\n",
    "    semantic_analysis,\n",
    "    labels=[f\"T{i}\" for i in range(1, len(technical_texts) + 1)]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example 3: Embedding Comparison\n",
    "\n",
    "Compare embeddings across different text styles."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compare formal vs informal texts\n",
    "similarity_matrix = interpreter.compare_embeddings(formal_texts, informal_texts)\n",
    "\n",
    "print(\"Cross-Style Similarity Matrix:\")\n",
    "print(f\"  Shape: {similarity_matrix.shape}\")\n",
    "print(f\"  Mean Similarity: {similarity_matrix.mean():.3f}\")\n",
    "print(f\"  Max Similarity: {similarity_matrix.max():.3f}\")\n",
    "print(f\"  Min Similarity: {similarity_matrix.min():.3f}\")\n",
    "\n",
    "print(\"\\nInterpretation: Lower similarity indicates distinct stylistic differences\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example 4: Reference Comparison\n",
    "\n",
    "Compare new texts against a reference set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# New texts to analyze\n",
    "new_texts = [\n",
    "    \"Transformers have revolutionized natural language understanding.\",\n",
    "    \"The weather is beautiful today.\"\n",
    "]\n",
    "\n",
    "# Reference texts (technical domain)\n",
    "reference_texts = [\n",
    "    \"Neural networks are the foundation of modern deep learning.\",\n",
    "    \"Machine learning models learn from data patterns.\",\n",
    "    \"Artificial intelligence continues to advance rapidly.\"\n",
    "]\n",
    "\n",
    "# Compare with references\n",
    "comparison = interpreter.analyze_semantics(new_texts, reference_texts=reference_texts)\n",
    "\n",
    "print(\"Reference Comparison Results:\")\n",
    "for comp in comparison['reference_comparison']['comparisons']:\n",
    "    print(f\"\\nInput: '{comp['input_text']}'\")\n",
    "    print(f\"  Most similar to: '{comp['most_similar_reference']}'\")\n",
    "    print(f\"  Similarity score: {comp['similarity_score']:.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example 5: Comprehensive Interpretation\n",
    "\n",
    "Perform a complete analysis combining style and semantics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mixed collection of texts\n",
    "mixed_texts = [\n",
    "    \"The experimental methodology demonstrates robust performance.\",\n",
    "    \"This is super exciting stuff for sure!\",\n",
    "    \"Deep learning architectures process sequential information.\",\n",
    "    \"Wow, these results are really impressive and cool.\",\n",
    "]\n",
    "\n",
    "print(\"Analyzing mixed text collection:\")\n",
    "for i, text in enumerate(mixed_texts, 1):\n",
    "    print(f\"{i}. {text}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Comprehensive interpretation\n",
    "results = interpreter.interpret(\n",
    "    mixed_texts,\n",
    "    include_style=True,\n",
    "    include_semantics=True\n",
    ")\n",
    "\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"Comprehensive Interpretation Results\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "print(f\"\\nModel: {results['model']}\")\n",
    "print(f\"Number of texts: {len(results['texts'])}\")\n",
    "\n",
    "print(\"\\nStyle Analysis:\")\n",
    "print(f\"  Mean Formality: {results['style_analysis']['formality']['mean_formality']:.3f}\")\n",
    "print(f\"  Mean Complexity: {results['style_analysis']['complexity']['mean_complexity']:.3f}\")\n",
    "print(f\"  Sentiment: {results['style_analysis']['sentiment']['polarity']}\")\n",
    "\n",
    "print(\"\\nSemantic Analysis:\")\n",
    "print(f\"  Coherence: {results['semantic_analysis']['coherence']['coherence_score']:.3f}\")\n",
    "print(f\"  Interpretation: {results['semantic_analysis']['coherence']['interpretation']}\")\n",
    "\n",
    "if 'clusters' in results['semantic_analysis']:\n",
    "    print(f\"  Detected Clusters: {results['semantic_analysis']['clusters']['n_clusters']}\")\n",
    "    cluster_labels = results['semantic_analysis']['clusters']['labels']\n",
    "    print(f\"  Cluster Labels: {cluster_labels}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize comprehensive results\n",
    "plot_comprehensive_analysis(\n",
    "    results,\n",
    "    text_labels=[f\"Text {i}\" for i in range(1, len(mixed_texts) + 1)]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example 6: Custom Embedding Extraction\n",
    "\n",
    "Extract and work with raw embeddings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract embeddings with different configurations\n",
    "sample_texts = [\n",
    "    \"Natural language processing.\",\n",
    "    \"Computer vision systems.\"\n",
    "]\n",
    "\n",
    "# Mean pooling (default)\n",
    "mean_emb = interpreter.get_embeddings(sample_texts, pooling='mean')\n",
    "print(f\"Mean pooling embeddings shape: {mean_emb.shape}\")\n",
    "\n",
    "# CLS token\n",
    "cls_emb = interpreter.get_embeddings(sample_texts, pooling='cls')\n",
    "print(f\"CLS token embeddings shape: {cls_emb.shape}\")\n",
    "\n",
    "# Max pooling\n",
    "max_emb = interpreter.get_embeddings(sample_texts, pooling='max')\n",
    "print(f\"Max pooling embeddings shape: {max_emb.shape}\")\n",
    "\n",
    "# Different layer\n",
    "layer_emb = interpreter.get_embeddings(sample_texts, layer=-2)\n",
    "print(f\"Layer -2 embeddings shape: {layer_emb.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusion\n",
    "\n",
    "This notebook demonstrated the key capabilities of the Transformer Embedding Interpretation framework:\n",
    "\n",
    "1. **Style Analysis**: Analyzing formality, complexity, and sentiment\n",
    "2. **Semantic Analysis**: Understanding content, coherence, and relationships\n",
    "3. **Embedding Comparison**: Comparing texts across different styles\n",
    "4. **Reference Matching**: Finding similar texts in a reference set\n",
    "5. **Comprehensive Interpretation**: Combining all analyses\n",
    "6. **Custom Extraction**: Flexible embedding extraction options\n",
    "\n",
    "The framework provides interpretable insights into how transformer models represent text at both stylistic and semantic levels."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
